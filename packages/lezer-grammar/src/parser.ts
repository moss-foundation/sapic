// This file was generated by lezer-generator. You probably shouldn't edit it.
import { LRParser } from "@lezer/lr";
import { rawTokenizer } from "./tokens";
import { highlight } from "./highlight";
export const parser = LRParser.deserialize({
  version: 14,
  states:
    "!dQQOROOO]OQO'#C_ObOQO'#CcOOOP'#Ch'#ChOOOP'#Cf'#CfQQOROOOgOQO,58yOlOQO,58}OOOP-E6d-E6dOOOP1G.e1G.eOOOP1G.i1G.i",
  stateData: "q~OPROSPOWQO~OTUO~OXVO~OUXO~OTYO~O",
  goto: "l]PPP^PPP^PPbPhTROTQTORWTTSOT",
  nodeNames: "âš  Raw Input Variable VarStart Identifier VarEnd PathParam Slash PathMarker",
  maxTerm: 12,
  propSources: [highlight],
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData:
    "!n~RW!P!Qk!Q![p![!]!R!c!}p#R#Sp#T#op#o#p!W#q#r!c~pOW~~uST~!Q![p!c!}p#R#Sp#T#op~!WOX~~!ZP#o#p!^~!cOS~~!fP#q#r!i~!nOU~",
  tokenizers: [rawTokenizer, 0],
  topRules: { "Input": [0, 2] },
  tokenPrec: 0,
});
